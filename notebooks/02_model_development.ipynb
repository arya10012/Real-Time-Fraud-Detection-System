{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection Model Development\n",
    "\n",
    "This notebook demonstrates the complete machine learning pipeline for fraud detection:\n",
    "\n",
    "1. **Data Generation & Loading**\n",
    "2. **Advanced Feature Engineering**\n",
    "3. **Individual Model Training & Evaluation**\n",
    "4. **Ensemble Model Development**\n",
    "5. **Model Explainability with SHAP**\n",
    "6. **Performance Analysis & Visualization**\n",
    "7. **Model Persistence**\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Arya Bhor  \n",
    "**Date**: January 2026 \n",
    "**Objective**: Build production-ready fraud detection system with 95%+ accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful\n",
      "âœ… Libraries imported successfully!\n",
      "ðŸ“… Training started at: 2026-01-09 20:09:43\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_processing import (\n",
    "    FraudDatasetGenerator,\n",
    "    DatasetConfig,\n",
    "    generate_and_save_data,\n",
    "    AdvancedFeatureEngineering\n",
    ")\n",
    "\n",
    "print(\"âœ… All imports successful\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"ðŸ“… Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_fraud_dataset' from 'data_processing.generate_data' (C:\\Users\\Arya\\OneDrive\\Desktop\\Certificates\\fraud-detection-system\\fraud-detection-system\\notebooks\\../src\\data_processing\\generate_data.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../src\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_processing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerate_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_fraud_dataset\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_processing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_engineering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdvancedFeatureEngineering\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfraud_detector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     RandomForestDetector, \n\u001b[32m     10\u001b[39m     XGBoostDetector, \n\u001b[32m     11\u001b[39m     LogisticRegressionDetector,\n\u001b[32m     12\u001b[39m     EnsembleFraudDetector\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'create_fraud_dataset' from 'data_processing.generate_data' (C:\\Users\\Arya\\OneDrive\\Desktop\\Certificates\\fraud-detection-system\\fraud-detection-system\\notebooks\\../src\\data_processing\\generate_data.py)"
     ]
    }
   ],
   "source": [
    "# Import custom modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_processing.generate_data import create_fraud_dataset\n",
    "from data_processing.feature_engineering import AdvancedFeatureEngineering\n",
    "from models.fraud_detector import (\n",
    "    RandomForestDetector, \n",
    "    XGBoostDetector, \n",
    "    LogisticRegressionDetector,\n",
    "    EnsembleFraudDetector\n",
    ")\n",
    "\n",
    "print(\"âœ… Custom modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creating synthetic fraud dataset...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_fraud_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create a substantial dataset for training\u001b[39;00m\n\u001b[32m      5\u001b[39m DATASET_SIZE = \u001b[32m50000\u001b[39m  \u001b[38;5;66;03m# Increase for more robust training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = \u001b[43mcreate_fraud_dataset\u001b[49m(n_samples=DATASET_SIZE)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ“Š Dataset created with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m transactions\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸŽ¯ Fraud rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m].mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m].mean()*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'create_fraud_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate synthetic fraud dataset\n",
    "print(\"ðŸ”„ Creating synthetic fraud dataset...\")\n",
    "\n",
    "# Create a substantial dataset for training\n",
    "DATASET_SIZE = 50000  # Increase for more robust training\n",
    "\n",
    "df = create_fraud_dataset(n_samples=DATASET_SIZE)\n",
    "\n",
    "print(f\"ðŸ“Š Dataset created with {len(df):,} transactions\")\n",
    "print(f\"ðŸŽ¯ Fraud rate: {df['Class'].mean():.4f} ({df['Class'].mean()*100:.2f}%)\")\n",
    "print(f\"ðŸ’° Average transaction amount: ${df['Amount'].mean():.2f}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nðŸ“ˆ Dataset Overview:\")\n",
    "display(df.describe())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ 2. Advanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Initializing advanced feature engineering pipeline...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m fe_pipeline = AdvancedFeatureEngineering(target_column=\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Apply comprehensive feature engineering\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df_engineered = fe_pipeline.fit_transform(\u001b[43mdf\u001b[49m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“Š Feature Engineering Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize feature engineering pipeline\n",
    "print(\"ðŸ”§ Initializing advanced feature engineering pipeline...\")\n",
    "\n",
    "fe_pipeline = AdvancedFeatureEngineering(target_column='Class')\n",
    "\n",
    "# Apply comprehensive feature engineering\n",
    "df_engineered = fe_pipeline.fit_transform(df)\n",
    "\n",
    "print(f\"\\nðŸ“Š Feature Engineering Results:\")\n",
    "print(f\"Original features: {df.shape[1]}\")\n",
    "print(f\"Engineered features: {df_engineered.shape[1]}\")\n",
    "print(f\"Features added: {df_engineered.shape[1] - df.shape[1]}\")\n",
    "\n",
    "# Show feature engineering summary\n",
    "feature_summary = fe_pipeline.get_feature_importance_summary()\n",
    "print(f\"\\nðŸŽ¯ Selected features: {feature_summary['total_features_created']}\")\n",
    "print(f\"ðŸ“ Encoders fitted: {len(feature_summary['encoders_fitted'])}\")\n",
    "print(f\"ðŸ“ Scalers fitted: {len(feature_summary['scalers_fitted'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– 3. Individual Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_engineered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Prepare features and target\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X = \u001b[43mdf_engineered\u001b[49m.drop(\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m y = df_engineered[\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸŽ¯ Final dataset for training:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_engineered' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = df_engineered.drop('Class', axis=1)\n",
    "y = df_engineered['Class']\n",
    "\n",
    "print(f\"ðŸŽ¯ Final dataset for training:\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"Class distribution: {dict(y.value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ 4. Ensemble Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Training Ensemble Fraud Detector...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EnsembleFraudDetector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train ensemble model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸŽ¯ Training Ensemble Fraud Detector...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ensemble = \u001b[43mEnsembleFraudDetector\u001b[49m(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      5\u001b[39m ensemble.train(X, y, test_size=\u001b[32m0.2\u001b[39m, balance_data=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ… Ensemble training completed!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'EnsembleFraudDetector' is not defined"
     ]
    }
   ],
   "source": [
    "# Train ensemble model\n",
    "print(\"ðŸŽ¯ Training Ensemble Fraud Detector...\")\n",
    "\n",
    "ensemble = EnsembleFraudDetector(random_state=42)\n",
    "ensemble.train(X, y, test_size=0.2, balance_data=True)\n",
    "\n",
    "print(f\"\\nâœ… Ensemble training completed!\")\n",
    "print(f\"ðŸŽ¯ Ensemble F1 Score: {ensemble.ensemble_metrics['f1_score']:.4f}\")\n",
    "print(f\"ðŸŽ¯ Ensemble ROC-AUC: {ensemble.ensemble_metrics['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ 5. Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensemble' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m joblib.dump(fe_pipeline, \u001b[33m'\u001b[39m\u001b[33m../models/feature_engineering_pipeline.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Save ensemble model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mensemble\u001b[49m.save_ensemble(\u001b[33m'\u001b[39m\u001b[33m../models/fraud_detection_ensemble.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… All models saved successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'ensemble' is not defined"
     ]
    }
   ],
   "source": [
    "# Save trained models\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save feature engineering pipeline\n",
    "joblib.dump(fe_pipeline, '../models/feature_engineering_pipeline.pkl')\n",
    "\n",
    "# Save ensemble model\n",
    "ensemble.save_ensemble('../models/fraud_detection_ensemble.pkl')\n",
    "\n",
    "print(\"âœ… All models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š 6. Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ FRAUD DETECTION MODEL TRAINING COMPLETE!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Print final summary\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸŽ¯ FRAUD DETECTION MODEL TRAINING COMPLETE!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ“Š Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mdf\u001b[49m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m transactions\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸŽ¯ Final Performance:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metric, value \u001b[38;5;129;01min\u001b[39;00m ensemble.ensemble_metrics.items():\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Print final summary\n",
    "print(\"ðŸŽ¯ FRAUD DETECTION MODEL TRAINING COMPLETE!\")\n",
    "print(f\"ðŸ“Š Dataset: {len(df):,} transactions\")\n",
    "print(f\"ðŸŽ¯ Final Performance:\")\n",
    "for metric, value in ensemble.ensemble_metrics.items():\n",
    "    print(f\"  â€¢ {metric.replace('_', ' ').title()}: {value:.4f}\")\n",
    "print(\"ðŸš€ Ready for production deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
